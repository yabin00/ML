{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43828cf6",
   "metadata": {},
   "source": [
    "## 书中中文分词示例的MindSpore实现\n",
    "\n",
    "该实现完全参考了MindSpore官网上r1.7的“LSTM+CRF实现序列标注”教程。该教程网址为：https://www.mindspore.cn/tutorials/application/zh-CN/r1.7/nlp/sequence_labeling.html\n",
    "\n",
    "其中条件随机场部分代码的原理，可参考官网和原版书相关内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d09936ad-6b20-4423-9f57-8e14917e61d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(emissions, tags, seq_ends, mask, trans, start_trans, end_trans):\n",
    "    # emissions: (seq_length, batch_size, num_tags)\n",
    "    # tags: (seq_length, batch_size)\n",
    "    # mask: (seq_length, batch_size)\n",
    "\n",
    "    seq_length, batch_size = tags.shape\n",
    "    mask = mask.astype(emissions.dtype)\n",
    "\n",
    "    # 将score设置为初始转移概率\n",
    "    # shape: (batch_size,)\n",
    "    score = start_trans[tags[0]]\n",
    "    # score += 第一次发射概率\n",
    "    # shape: (batch_size,)\n",
    "    score += emissions[0, mnp.arange(batch_size), tags[0]]\n",
    "\n",
    "    for i in range(1, seq_length):\n",
    "        # 标签由i-1转移至i的转移概率（当mask == 1时有效）\n",
    "        # shape: (batch_size,)\n",
    "        score += trans[tags[i - 1], tags[i]] * mask[i]\n",
    "\n",
    "        # 预测tags[i]的发射概率（当mask == 1时有效）\n",
    "        # shape: (batch_size,)\n",
    "        score += emissions[i, mnp.arange(batch_size), tags[i]] * mask[i]\n",
    "\n",
    "    # 结束转移\n",
    "    # shape: (batch_size,)\n",
    "    last_tags = tags[seq_ends, mnp.arange(batch_size)]\n",
    "    # score += 结束转移概率\n",
    "    # shape: (batch_size,)\n",
    "    score += end_trans[last_tags]\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a0ef6a-1c3a-400e-9053-e0659e8f9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normalizer(emissions, mask, trans, start_trans, end_trans):\n",
    "    # emissions: (seq_length, batch_size, num_tags)\n",
    "    # mask: (seq_length, batch_size)\n",
    "\n",
    "    seq_length = emissions.shape[0]\n",
    "\n",
    "    # 将score设置为初始转移概率，并加上第一次发射概率\n",
    "    # shape: (batch_size, num_tags)\n",
    "    score = start_trans + emissions[0]\n",
    "\n",
    "    for i in range(1, seq_length):\n",
    "        # 扩展score的维度用于总score的计算\n",
    "        # shape: (batch_size, num_tags, 1)\n",
    "        broadcast_score = score.expand_dims(2)\n",
    "\n",
    "        # 扩展emission的维度用于总score的计算\n",
    "        # shape: (batch_size, 1, num_tags)\n",
    "        broadcast_emissions = emissions[i].expand_dims(1)\n",
    "\n",
    "        # 根据公式(7)，计算score_i\n",
    "        # 此时broadcast_score是由第0个到当前Token所有可能路径\n",
    "        # 对应score的log_sum_exp\n",
    "        # shape: (batch_size, num_tags, num_tags)\n",
    "        next_score = broadcast_score + trans + broadcast_emissions\n",
    "\n",
    "        # 对score_i做log_sum_exp运算，用于下一个Token的score计算\n",
    "        # shape: (batch_size, num_tags)\n",
    "        next_score = mnp.log(mnp.sum(mnp.exp(next_score), axis=1))\n",
    "\n",
    "        # 当mask == 1时，score才会变化\n",
    "        # shape: (batch_size, num_tags)\n",
    "        score = mnp.where(mask[i].expand_dims(1), next_score, score)\n",
    "\n",
    "    # 最后加结束转移概率\n",
    "    # shape: (batch_size, num_tags)\n",
    "    score += end_trans\n",
    "    # 对所有可能的路径得分求log_sum_exp\n",
    "    # shape: (batch_size,)\n",
    "    return mnp.log(mnp.sum(mnp.exp(score), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c286935-74eb-413a-8e47-b8fb5264e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decode(emissions, mask, trans, start_trans, end_trans):\n",
    "    # emissions: (seq_length, batch_size, num_tags)\n",
    "    # mask: (seq_length, batch_size)\n",
    "\n",
    "    seq_length = mask.shape[0]\n",
    "\n",
    "    score = start_trans + emissions[0]\n",
    "    history = ()\n",
    "\n",
    "    for i in range(1, seq_length):\n",
    "        broadcast_score = score.expand_dims(2)\n",
    "        broadcast_emission = emissions[i].expand_dims(1)\n",
    "        next_score = broadcast_score + trans + broadcast_emission\n",
    "\n",
    "        # 求当前Token对应score取值最大的标签，并保存\n",
    "        indices = next_score.argmax(axis=1)\n",
    "        history += (indices,)\n",
    "\n",
    "        next_score = next_score.max(axis=1)\n",
    "        score = mnp.where(mask[i].expand_dims(1), next_score, score)\n",
    "\n",
    "    score += end_trans\n",
    "\n",
    "    return score, history\n",
    "\n",
    "def post_decode(score, history, seq_length):\n",
    "    # 使用Score和History计算最佳预测序列\n",
    "    batch_size = seq_length.shape[0]\n",
    "    seq_ends = seq_length - 1\n",
    "    # shape: (batch_size,)\n",
    "    best_tags_list = []\n",
    "\n",
    "    # 依次对一个Batch中每个样例进行解码\n",
    "    for idx in range(batch_size):\n",
    "        # 查找使最后一个Token对应的预测概率最大的标签，\n",
    "        # 并将其添加至最佳预测序列存储的列表中\n",
    "        best_last_tag = score[idx].argmax(axis=0)\n",
    "        best_tags = [int(best_last_tag.asnumpy())]\n",
    "\n",
    "        # 重复查找每个Token对应的预测概率最大的标签，加入列表\n",
    "        for hist in reversed(history[:seq_ends[idx]]):\n",
    "            best_last_tag = hist[idx][best_tags[-1]]\n",
    "            best_tags.append(int(best_last_tag.asnumpy()))\n",
    "\n",
    "        # 将逆序求解的序列标签重置为正序\n",
    "        best_tags.reverse()\n",
    "        best_tags_list.append(best_tags)\n",
    "\n",
    "    return best_tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "120a39c7-c89d-4cd3-8a75-da27d2853f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import mindspore.numpy as mnp\n",
    "from mindspore import Parameter\n",
    "from mindspore.common.initializer import initializer, Uniform\n",
    "\n",
    "def sequence_mask(seq_length, max_length, batch_first=False):\n",
    "    \"\"\"根据序列实际长度和最大长度生成mask矩阵\"\"\"\n",
    "    range_vector = mnp.arange(0, max_length, 1, seq_length.dtype)\n",
    "    result = range_vector < seq_length.view(seq_length.shape + (1,))\n",
    "    if batch_first:\n",
    "        return result.astype(mindspore.int64)\n",
    "    return result.astype(mindspore.int64).swapaxes(0, 1)\n",
    "\n",
    "class CRF(nn.Cell):\n",
    "    def __init__(self, num_tags: int, batch_first: bool = False, reduction: str = 'sum') -> None:\n",
    "        if num_tags <= 0:\n",
    "            raise ValueError(f'invalid number of tags: {num_tags}')\n",
    "        super().__init__()\n",
    "        if reduction not in ('none', 'sum', 'mean', 'token_mean'):\n",
    "            raise ValueError(f'invalid reduction: {reduction}')\n",
    "        self.num_tags = num_tags\n",
    "        self.batch_first = batch_first\n",
    "        self.reduction = reduction\n",
    "        self.start_transitions = Parameter(initializer(Uniform(0.1), (num_tags,)), name='start_transitions')\n",
    "        self.end_transitions = Parameter(initializer(Uniform(0.1), (num_tags,)), name='end_transitions')\n",
    "        self.transitions = Parameter(initializer(Uniform(0.1), (num_tags, num_tags)), name='transitions')\n",
    "\n",
    "    def construct(self, emissions, tags=None, seq_length=None):\n",
    "        if tags is None:\n",
    "            return self._decode(emissions, seq_length)\n",
    "        return self._forward(emissions, tags, seq_length)\n",
    "\n",
    "    def _forward(self, emissions, tags=None, seq_length=None):\n",
    "        if self.batch_first:\n",
    "            batch_size, max_length = tags.shape\n",
    "            emissions = emissions.swapaxes(0, 1)\n",
    "            tags = tags.swapaxes(0, 1)\n",
    "        else:\n",
    "            max_length, batch_size = tags.shape\n",
    "\n",
    "        if seq_length is None:\n",
    "            seq_length = mnp.full((batch_size,), max_length, mindspore.int64)\n",
    "\n",
    "        mask = sequence_mask(seq_length, max_length)\n",
    "\n",
    "        # shape: (batch_size,)\n",
    "        numerator = compute_score(emissions, tags, seq_length-1, mask, self.transitions, self.start_transitions, self.end_transitions)\n",
    "        # shape: (batch_size,)\n",
    "        denominator = compute_normalizer(emissions, mask, self.transitions, self.start_transitions, self.end_transitions)\n",
    "        # shape: (batch_size,)\n",
    "        llh = denominator - numerator\n",
    "\n",
    "        if self.reduction == 'none':\n",
    "            return llh\n",
    "        if self.reduction == 'sum':\n",
    "            return llh.sum()\n",
    "        if self.reduction == 'mean':\n",
    "            return llh.mean()\n",
    "        return llh.sum() / mask.astype(emissions.dtype).sum()\n",
    "\n",
    "    def _decode(self, emissions, seq_length=None):\n",
    "        if self.batch_first:\n",
    "            batch_size, max_length = emissions.shape[:2]\n",
    "            emissions = emissions.swapaxes(0, 1)\n",
    "        else:\n",
    "            batch_size, max_length = emissions.shape[:2]\n",
    "\n",
    "        if seq_length is None:\n",
    "            seq_length = mnp.full((batch_size,), max_length, mindspore.int64)\n",
    "\n",
    "        mask = sequence_mask(seq_length, max_length)\n",
    "\n",
    "        return viterbi_decode(emissions, mask, self.transitions, self.start_transitions, self.end_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07555e3-f2a2-4c25-beff-5a78491ab2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Cell):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_tags, padding_idx=0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, bidirectional=True, batch_first=True)\n",
    "        self.hidden2tag = nn.Dense(hidden_dim, num_tags, 'he_uniform')\n",
    "        self.crf = CRF(num_tags, batch_first=True)\n",
    "\n",
    "    def construct(self, inputs, seq_length, tags=None):\n",
    "        embeds = self.embedding(inputs)\n",
    "        outputs, _ = self.lstm(embeds, seq_length=seq_length)\n",
    "        feats = self.hidden2tag(outputs)\n",
    "\n",
    "        crf_outs = self.crf(feats, tags, seq_length)\n",
    "        return crf_outs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c7b69",
   "metadata": {},
   "source": [
    "## 以上为官网上实现的模型，下面用该模型来实现中文分词示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233ec594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本准备完毕！\n",
      "共有数据 62946 条\n",
      "平均长度： 8.67100371747212\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "file = open(\"traindata.txt\", encoding='utf-8')\n",
    "test_str = \"中国首次火星探测任务天问一号探测器实施近火捕获制动\"\n",
    "\n",
    "new_sents = []\n",
    "sents_labels = []\n",
    "for line in file.readlines():\n",
    "    line = line.split()\n",
    "    new_sent = ''\n",
    "    sent_labels = ''\n",
    "    for word in line:\n",
    "        if len(word) == 1:\n",
    "            new_sent += word\n",
    "            sent_labels += 'S'\n",
    "        elif len(word) >= 2:\n",
    "            new_sent += word\n",
    "            sent_labels += 'B' + 'M'*(len(word)-2) + 'E'\n",
    "    if new_sent != '':\n",
    "        new_sents.append([new_sent])\n",
    "        sents_labels.append([sent_labels])\n",
    "print(\"训练样本准备完毕！\")\n",
    "print('共有数据 %d 条' % len(new_sents))\n",
    "print('平均长度：', np.mean([len(d[0]) for d in new_sents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70f22a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# 重要参数\n",
    "tags = {'S': 0, 'B': 1, 'M': 2, 'E': 3, 'X': 4} # 标签\n",
    "embedding_size = 32 # 词向量大小\n",
    "maxlen = 32 # 序列长度，长于则截断，短于则填充0\n",
    "hidden_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfeb1cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不同字的个数：3878\n",
      "字典创建完毕！\n"
     ]
    }
   ],
   "source": [
    "# 1.提取出所有用到的字，形成字典\n",
    "stat = {}\n",
    "for i in range(len(new_sents)):\n",
    "    for v in new_sents[i][0]:\n",
    "        stat[v] = stat.get(v, 0) + 1\n",
    "stat = sorted(stat.items(), key=lambda x:x[1], reverse=True)\n",
    "vocab = [s[0] for s in stat]\n",
    "print(\"不同字的个数：\" + str(len(vocab)))\n",
    "char2id = {c : i + 1 for i, c in enumerate(vocab)} # 编号0为填充值，因此从1开始编号\n",
    "id2char = {i + 1 : c for i, c in enumerate(vocab)}\n",
    "print(\"字典创建完毕！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c51487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本准备完毕，训练样本共62946句。\n"
     ]
    }
   ],
   "source": [
    "# 2.将训练语句转化为训练样本\n",
    "trainX = []\n",
    "trainX_len = []\n",
    "trainY = []\n",
    "for i in range(len(new_sents)):\n",
    "    x = [0] * maxlen # 默认填充值\n",
    "    y = [4] * maxlen # 默认标签X\n",
    "    sent = new_sents[i][0]\n",
    "    labe = sents_labels[i][0]\n",
    "    replace_len = len(sent)\n",
    "    if len(sent) > maxlen:\n",
    "        replace_len = maxlen\n",
    "    for j in range(replace_len):\n",
    "        x[j] = char2id[sent[j]]\n",
    "        y[j] = tags[labe[j]]\n",
    "    trainX.append(x)\n",
    "    trainX_len.append(len(sent))\n",
    "    trainY.append(y)\n",
    "trainX = np.array(trainX)\n",
    "trainX_len = np.array(trainX_len)\n",
    "trainY = np.array(trainY)\n",
    "#trainY = tf.keras.utils.to_categorical(trainY, 5)\n",
    "print(\"训练样本准备完毕，训练样本共\" + str(len(trainX)) + \"句。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c8fb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = mindspore.Tensor(trainX, mindspore.int64)\n",
    "trainX_len = mindspore.Tensor(trainX_len, mindspore.int64)\n",
    "trainY = mindspore.Tensor(trainY, mindspore.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c2be58b-b61c-4a64-ae14-c46a959988c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.搭建模型，并训练\n",
    "\n",
    "model = BiLSTM_CRF(len(char2id)+1, embedding_size, hidden_size, len(tags))\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=0.01, weight_decay=1e-4)\n",
    "\n",
    "train_one_step = nn.TrainOneStepCell(model, optimizer)\n",
    "\n",
    "train_one_step.compile(trainX, trainX_len, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46595499-c50e-48ea-82ff-e006b00aba12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 10/10 [1:03:49<00:00, 382.92s/it, loss=578476.4]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "steps = 3\n",
    "with tqdm(total=steps) as t:\n",
    "    for i in range(steps):\n",
    "        loss = train_one_step(trainX, trainX_len, trainY)\n",
    "        t.set_postfix(loss=loss)\n",
    "        t.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79757c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.利用训练好的模型进行分词\n",
    "def predict(testsent):\n",
    "    # 将汉字句子转换成模型需要的输入形式\n",
    "    x = [0] * maxlen\n",
    "    replace_len = len(testsent)\n",
    "    if len(testsent) > maxlen:\n",
    "        replace_len = maxlen\n",
    "    for j in range(replace_len):\n",
    "        x[j] = char2id[testsent[j]]\n",
    "    # 调用模型进行预测\n",
    "    xx = mindspore.Tensor([x], mindspore.int64)\n",
    "    xx_len = mindspore.Tensor([len(testsent)], mindspore.int64)\n",
    "    score, history = model(xx, xx_len) \n",
    "    predict = post_decode(score, history, xx_len)\n",
    "    #print(predict)\n",
    "    # 根据模型预测结果对输入句子进行切分\n",
    "    label = np.array(predict)[0]\n",
    "    s = ''\n",
    "    for i in range(len(testsent)):\n",
    "        tag = label[i]\n",
    "        if tag == 0 or tag == 3: # 单字和词结尾加空格切分\n",
    "            s += testsent[i] + ' '\n",
    "        elif tag ==1 or tag == 2:\n",
    "            s += testsent[i]\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "185415e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国 首次 火星 探测 任务 天问 一号 探测器 实施 近火 捕获 制动 \n"
     ]
    }
   ],
   "source": [
    "predict(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b830d555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
