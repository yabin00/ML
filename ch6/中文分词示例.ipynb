{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练样本预处理 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本准备完毕！\n",
      "共有数据 62946 条\n",
      "平均长度： 8.67100371747212\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "file = open(\"traindata.txt\", encoding='utf-8')\n",
    "test_str = \"中国首次火星探测任务天问一号探测器实施近火捕获制动\"\n",
    "\n",
    "new_sents = []\n",
    "sents_labels = []\n",
    "for line in file.readlines():\n",
    "    line = line.split()\n",
    "    new_sent = ''\n",
    "    sent_labels = ''\n",
    "    for word in line:\n",
    "        if len(word) == 1:\n",
    "            new_sent += word\n",
    "            sent_labels += 'S'\n",
    "        elif len(word) >= 2:\n",
    "            new_sent += word\n",
    "            sent_labels += 'B' + 'M'*(len(word)-2) + 'E'\n",
    "    if new_sent != '':\n",
    "        new_sents.append([new_sent])\n",
    "        sents_labels.append([sent_labels])\n",
    "print(\"训练样本准备完毕！\")\n",
    "print('共有数据 %d 条' % len(new_sents))\n",
    "print('平均长度：', np.mean([len(d[0]) for d in new_sents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['坚持从严治党落实管党治党责任']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEBEBEBESSBEBE']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 隐马模型实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计初始概率矩阵pi\n",
    "state = ['S', 'B', 'M', 'E']\n",
    "pi = np.zeros(4)\n",
    "for i in range(len(sents_labels)):\n",
    "    if sents_labels[i][0][0] == 'S':\n",
    "        pi[0] += 1\n",
    "    if sents_labels[i][0][0] == 'B':\n",
    "        pi[1] += 1\n",
    "pi /= np.sum(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计转移概率矩阵A和观测概率矩阵B\n",
    "A = np.zeros((4, 4))\n",
    "B = np.zeros((4, 65536)) # GB2312编码\n",
    "for i in range(len(sents_labels)):\n",
    "    for j in range(len(sents_labels[i][0])):\n",
    "        B[state.index(sents_labels[i][0][j]), ord(new_sents[i][0][j])] += 1 # 观测频率加1\n",
    "    for j in range(len(sents_labels[i][0]) - 1):\n",
    "        A[state.index(sents_labels[i][0][j]), state.index(sents_labels[i][0][j+1])] += 1 # 转移频率加1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33219523 0.66780477 0.         0.        ]\n",
      " [0.         0.         0.13972527 0.86027473]\n",
      " [0.         0.         0.29685786 0.70314214]\n",
      " [0.34044534 0.65955466 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    if np.sum(A[i]) != 0:\n",
    "        A[i] = A[i] / np.sum(A[i])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    B[i] /= np.sum(B[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "model = hmm.MultinomialHMM(n_components=4)\n",
    "model.startprob_ = pi\n",
    "model.emissionprob_ = B\n",
    "model.transmat_ = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 1 3 1 3 1 3 1 3 0 1 2 3 1 2 3 1 3 1 3 1 3 1 3]\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "for i in range(len(test_str)): # 得到编码\n",
    "    test_data.append(ord(test_str[i]))\n",
    "test_data = np.array(test_data).reshape(-1, 1)\n",
    "states = model.predict(test_data)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国 首次 火星 探测 任务 天 问一号 探测器 实施 近火 捕获 制动\n"
     ]
    }
   ],
   "source": [
    "test_out = \"\"\n",
    "for i in range(len(states)):\n",
    "    test_out += test_str[i]\n",
    "    if states[i] == 0 or states[i] == 3:\n",
    "        test_out += ' '\n",
    "test_out = test_out.strip()\n",
    "print(test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 条件随机场实现 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练语料改成crf++的格式，并写入文件crf_train_file\n",
    "crf_train_file = \"crf_train_file\"\n",
    "output_file = open(crf_train_file, 'w', encoding='utf-8')\n",
    "for i in range(len(new_sents)):\n",
    "    for j in range(len(new_sents[i][0])):\n",
    "        output_file.write(new_sents[i][0][j] + ' ' + sents_labels[i][0][j] + '\\n')\n",
    "    output_file.write('\\n')\n",
    "output_file.close()\n",
    "\n",
    "# 将测试文本改成crf++的格式，并写入文件crf_test_file\n",
    "crf_test_file = \"crf_test_file\"\n",
    "output_file = open(crf_test_file, 'w', encoding='utf-8')\n",
    "for i in range(len(test_str)):\n",
    "    output_file.write(test_str[i] + '\\n')\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将crf_learn.exe、crf_test.exe、libcrfpp.dll文件拷贝到目录下，定义一个模板文件：template。在控制台环境下，执行“crf_learn template crf_train_file crf_model”命令进行训练，得到模型文件：crf_model。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  在控制台环境下，执行“crf_test -m crf_model crf_test_file > crf_test_output”命令得到测试语句的输出文件：crf_test_output。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国 首次 火星 探测 任务 天问 一 号 探测器 实施 近火 捕获 制动 \n"
     ]
    }
   ],
   "source": [
    "# 将测试语句的分词输出改写方便观看的格式。\n",
    "crf_test_output = \"crf_test_output\"\n",
    "input_file = open(crf_test_output, encoding='utf-8')\n",
    "str = \"\"\n",
    "for line in input_file.readlines():\n",
    "    line = line.split()\n",
    "    if len(line) == 2:\n",
    "        if line[1] == 'E' or line[1] == 'S':\n",
    "            str += line[0] + ' '\n",
    "        else:\n",
    "            str += line[0]\n",
    "input_file.close()\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow2框架下循环神经网络实现 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# 重要参数\n",
    "tags = {'S': 0, 'B': 1, 'M': 2, 'E': 3, 'X': 4} # 标签\n",
    "embedding_size = 32 # 词向量大小\n",
    "maxlen = 32 # 序列长度，长于则截断，短于则填充0\n",
    "hidden_size = 32\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "checkpointfilepath = 'weights.best.hdf5' # 中间结果保存文件\n",
    "modepath = 'dz.h5' # 模型保存文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不同字的个数：3878\n",
      "字典创建完毕！\n"
     ]
    }
   ],
   "source": [
    "# 1.提取出所有用到的字，形成字典\n",
    "stat = {}\n",
    "for i in range(len(new_sents)):\n",
    "    for v in new_sents[i][0]:\n",
    "        stat[v] = stat.get(v, 0) + 1\n",
    "stat = sorted(stat.items(), key=lambda x:x[1], reverse=True)\n",
    "vocab = [s[0] for s in stat]\n",
    "print(\"不同字的个数：\" + str(len(vocab)))\n",
    "char2id = {c : i + 1 for i, c in enumerate(vocab)} # 编号0为填充值，因此从1开始编号\n",
    "id2char = {i + 1 : c for i, c in enumerate(vocab)}\n",
    "print(\"字典创建完毕！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本准备完毕，训练样本共62946句。\n"
     ]
    }
   ],
   "source": [
    "# 2.将训练语句转化为训练样本\n",
    "trainX = []\n",
    "trainY = []\n",
    "for i in range(len(new_sents)):\n",
    "    x = [0] * maxlen # 默认填充值\n",
    "    y = [4] * maxlen # 默认标签X\n",
    "    sent = new_sents[i][0]\n",
    "    labe = sents_labels[i][0]\n",
    "    replace_len = len(sent)\n",
    "    if len(sent) > maxlen:\n",
    "        replace_len = maxlen\n",
    "    for j in range(replace_len):\n",
    "        x[j] = char2id[sent[j]]\n",
    "        y[j] = tags[labe[j]]\n",
    "    trainX.append(x)\n",
    "    trainY.append(y)\n",
    "trainX = np.array(trainX)\n",
    "trainY = tf.keras.utils.to_categorical(trainY, 5)\n",
    "print(\"训练样本准备完毕，训练样本共\" + str(len(trainX)) + \"句。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 32, 32)            124128    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 32, 64)            16640     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 32, 64)            24832     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 32, 5)             325       \n",
      "=================================================================\n",
      "Total params: 165,925\n",
      "Trainable params: 165,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 3.搭建模型，并训练\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Dropout, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "X = Input(shape=(maxlen,), dtype='int32')\n",
    "embedding = Embedding(input_dim=len(vocab)+1, output_dim=embedding_size, input_length=maxlen, mask_zero=True)(X)\n",
    "blstm = Bidirectional(LSTM(hidden_size, return_sequences=True), merge_mode='concat')(embedding)\n",
    "blstm = Dropout(0.4)(blstm)\n",
    "blstm = Bidirectional(LSTM(hidden_size, return_sequences=True), merge_mode='concat')(blstm)\n",
    "blstm = Dropout(0.4)(blstm)\n",
    "output = TimeDistributed(Dense(5, activation='softmax'))(blstm)\n",
    "model = Model(X, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984/984 [==============================] - 211s 181ms/step - loss: 0.1928 - accuracy: 0.7169\n",
      "WARNING:tensorflow:Can save best model only with acc available, skipping.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists(checkpointfilepath): # 与下面的checkpoint起到及时保存训练结果的作用\n",
    "    print(\"加载前次训练模型参数。。。\")\n",
    "    model.load_weights(checkpointfilepath)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "checkpoint = ModelCheckpoint(checkpointfilepath, monitor='acc', verbose=1, save_best_only=True,\n",
    "                            mode='max')\n",
    "model.fit(trainX, trainY, batch_size=batch_size, epochs=epochs, callbacks=[checkpoint])\n",
    "model.save(modepath)\n",
    "#print(model.evaluate(trainX, trainY, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.利用训练好的模型进行分词\n",
    "def predict(testsent):\n",
    "    # 将汉字句子转换成模型需要的输入形式\n",
    "    x = [0] * maxlen\n",
    "    replace_len = len(testsent)\n",
    "    if len(testsent) > maxlen:\n",
    "        replace_len = maxlen\n",
    "    for j in range(replace_len):\n",
    "        x[j] = char2id[testsent[j]]\n",
    "    # 调用模型进行预测\n",
    "    label = model.predict([x]) \n",
    "    # 根据模型预测结果对输入句子进行切分\n",
    "    label = np.array(label)[0]\n",
    "    s = ''\n",
    "    for i in range(len(testsent)):\n",
    "        tag = np.argmax(label[i])\n",
    "        if tag == 0 or tag == 3: # 单字和词结尾加空格切分\n",
    "            s += testsent[i] + ' '\n",
    "        elif tag ==1 or tag == 2:\n",
    "            s += testsent[i]\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国 首次 火星 探测 任务 天问 一 号 探测器 实施 近火 捕获 制动 \n"
     ]
    }
   ],
   "source": [
    "predict(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
